{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from bunch import Bunch\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from utils.helpers import get_instance\n",
    "import models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_url = \"https://farm1.staticflickr.com/6/9606553_ccc7518589_z.jpg\"\n",
    "image = np.array(Image.open(requests.get(image_url, stream=True).raw))\n",
    "rgb_img = np.float32(image) / 255\n",
    "input_tensor = preprocess_image(rgb_img,\n",
    "                                mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "# Taken from the torchvision tutorial\n",
    "# https://pytorch.org/vision/stable/auto_examples/plot_visualization_utils.html\n",
    "model = deeplabv3_resnet50(pretrained=True, progress=False)\n",
    "model = model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    input_tensor = input_tensor.cuda()\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(type(output), output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.dtype)\n",
    "print(rgb_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModelOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, model): \n",
    "        super(SegmentationModelOutputWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)[\"out\"]\n",
    "    \n",
    "model = SegmentationModelOutputWrapper(model)\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_masks = torch.nn.functional.softmax(output, dim=1).cpu()\n",
    "sem_classes = [\n",
    "    '__background__', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(sem_classes)}\n",
    "\n",
    "car_category = sem_class_to_idx[\"car\"]\n",
    "car_mask = normalized_masks[0, :, :, :].argmax(axis=0).detach().cpu().numpy()\n",
    "car_mask_uint8 = 255 * np.uint8(car_mask == car_category)\n",
    "car_mask_float = np.float32(car_mask == car_category)\n",
    "\n",
    "both_images = np.hstack((image, np.repeat(car_mask_uint8[:, :, None], 3, axis=-1)))\n",
    "Image.fromarray(both_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_masks.shape)\n",
    "print(normalized_masks.dtype)\n",
    "print(car_mask.shape)\n",
    "print(car_mask.dtype)\n",
    "print(car_mask_uint8.shape)\n",
    "print(car_mask_uint8.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        self.mask = torch.from_numpy(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask.cuda()\n",
    "        \n",
    "    def __call__(self, model_output):\n",
    "        return (model_output[self.category, :, : ] * self.mask).sum()\n",
    "\n",
    "    \n",
    "target_layers = [model.model.backbone.layer4]\n",
    "targets = [SemanticSegmentationTarget(car_category, car_mask_float)]\n",
    "with GradCAM(model=model,\n",
    "             target_layers=target_layers) as cam:\n",
    "    grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                        targets=targets)[0, :]\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "Image.fromarray(cam_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model FR-Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image size (565, 584, 3)\n",
    "##########################\n",
    "- input: \n",
    "torch.Size([1, 1, 592, 592]) <br>\n",
    "torch.float32<br>\n",
    "\n",
    "- model:\n",
    "'<class 'torch.nn.parallel.data_parallel.DataParallel'>'\n",
    "\n",
    "- output:\n",
    "'<class 'torch.Tensor'>'<br>\n",
    "torch.Size([1, 1, 592, 592])<br>\n",
    "torch.float32\n",
    "torch.float32\n",
    "\n",
    "Inference Pipeline:\n",
    "1. Padding input, make sure input in shape 592\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = YAML(typ='safe', pure=True)\n",
    "\n",
    "with open(\"config.yaml\", encoding=\"utf-8\") as file:\n",
    "    CFG = Bunch(yaml.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInference:\n",
    "    def __init__(self, model, weight_path, device=None, input_size=592):\n",
    "        self.device = torch.device(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        self.model = nn.DataParallel(model.to(self.device)) if torch.cuda.is_available() else model.to(self.device)\n",
    "        self.input_size = input_size\n",
    "        self.checkpoint = torch.load(weight_path)\n",
    "        self.model.load_state_dict(self.checkpoint['state_dict'])\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    def _read_image(self, image_path: str) -> np.ndarray:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "        return img\n",
    "\n",
    "    def _resize_image(self, raw_image):\n",
    "        return cv2.resize(raw_image, (self.input_size, self.input_size), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    def _pad_image(self, raw_image):\n",
    "        \"\"\"\n",
    "        Pad image to the input_size if the image dimensions are less than input_size.\n",
    "        \"\"\"\n",
    "        h, w = raw_image.shape\n",
    "        pad_h = self.input_size - h \n",
    "        pad_w = self.input_size - w \n",
    "        return F.pad(torch.tensor(raw_image), (0, pad_w, 0, pad_h), mode=\"constant\", value=0).numpy()\n",
    "\n",
    "    def preprocess_image(self, raw_image):\n",
    "        \"\"\"\n",
    "        Preprocesses the input image by either resizing or padding it to match the input_size.\n",
    "        \"\"\"\n",
    "        h, w = raw_image.shape\n",
    "        \n",
    "        if h < self.input_size or w < self.input_size:\n",
    "            preproc_image = self._pad_image(raw_image)\n",
    "        elif h > self.input_size or w > self.input_size:\n",
    "            preproc_image = self._resize_image(raw_image)\n",
    "\n",
    "        return ToTensor()(preproc_image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict(self, image_tensor):\n",
    "        \"\"\"\n",
    "        Run inference on the preprocessed image tensor using the model.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(image_tensor)\n",
    "            return torch.sigmoid(prediction).squeeze().cpu().numpy()\n",
    "\n",
    "    def postprocess_output(self, prediction, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Postprocess the prediction to obtain a binary mask.\n",
    "        \"\"\"\n",
    "        return (prediction >= threshold).astype(np.uint8)\n",
    "\n",
    "    def save_output(self, binary_mask, output_path):\n",
    "        \"\"\"\n",
    "        Save the binary mask as an image.\n",
    "        \"\"\"\n",
    "        cv2.imwrite(output_path, binary_mask * 255)\n",
    "\n",
    "    def infer(self, image_path, output_path=None, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Run the full inference pipeline: read image, preprocess, predict, postprocess, and save output.\n",
    "        \"\"\"\n",
    "        # Read the raw image\n",
    "        raw_image = self._read_image(image_path)\n",
    "\n",
    "        # Preprocess the image\n",
    "        image_tensor = self.preprocess_image(raw_image)\n",
    "        print(type(image_tensor))\n",
    "        print(image_tensor.shape)\n",
    "        # Make a prediction\n",
    "        prediction = self.predict(image_tensor)\n",
    "        print(type(prediction))\n",
    "         \n",
    "\n",
    "        # Postprocess the prediction into a binary mask\n",
    "        binary_mask = self.postprocess_output(prediction, threshold)\n",
    "\n",
    "        # Save the output mask if output_path is provided\n",
    "        if output_path:\n",
    "            self.save_output(binary_mask, output_path)\n",
    "\n",
    "        return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 1, 592, 592])\n",
      "<class 'numpy.ndarray'>\n",
      "Processed C:\\\\Users\\\\UCL\\\\Desktop\\\\Do\\\\datasets\\\\DRIVE\\\\DRIVE\\\\test\\\\images\\\\01_test.tif, result shape: (592, 592)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = get_instance(models, 'model', CFG)\n",
    "checkpoint = \"pretrained_weights/DRIVE/checkpoint-epoch40.pth\"\n",
    "\n",
    "# Initialize inference class\n",
    "inference = ModelInference(model, checkpoint)\n",
    "\n",
    "# Run inference on a single image\n",
    "image_path = r'C:\\\\Users\\\\UCL\\\\Desktop\\\\Do\\\\datasets\\\\DRIVE\\\\DRIVE\\\\test\\\\images\\\\01_test.tif'\n",
    "output_path = \"output_mask.png\"\n",
    "binary_mask = inference.infer(image_path, output_path)\n",
    "\n",
    "# Print result shape\n",
    "print(f\"Processed {image_path}, result shape: {binary_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(binary_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def binarize(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Binarizes the prediction and ground truth using a threshold.\n",
    "        \"\"\"\n",
    "        prediction_bin = (prediction >= self.threshold).astype(np.uint8)\n",
    "        ground_truth_bin = (ground_truth >= self.threshold).astype(np.uint8)\n",
    "        return prediction_bin, ground_truth_bin\n",
    "\n",
    "    def accuracy(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates accuracy.\n",
    "        \"\"\"\n",
    "        prediction_bin, ground_truth_bin = self.binarize(prediction, ground_truth)\n",
    "        return accuracy_score(ground_truth_bin.flatten(), prediction_bin.flatten())\n",
    "\n",
    "    def sensitivity(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates sensitivity (True Positive Rate).\n",
    "        \"\"\"\n",
    "        prediction_bin, ground_truth_bin = self.binarize(prediction, ground_truth)\n",
    "        cm = confusion_matrix(ground_truth_bin.flatten(), prediction_bin.flatten())\n",
    "        tp = cm[1, 1]\n",
    "        fn = cm[1, 0]\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    def specificity(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates specificity (True Negative Rate).\n",
    "        \"\"\"\n",
    "        prediction_bin, ground_truth_bin = self.binarize(prediction, ground_truth)\n",
    "        cm = confusion_matrix(ground_truth_bin.flatten(), prediction_bin.flatten())\n",
    "        tn = cm[0, 0]\n",
    "        fp = cm[0, 1]\n",
    "        return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    def f1_score(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates F1 score.\n",
    "        \"\"\"\n",
    "        prediction_bin, ground_truth_bin = self.binarize(prediction, ground_truth)\n",
    "        return f1_score(ground_truth_bin.flatten(), prediction_bin.flatten())\n",
    "\n",
    "    def auc(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates AUC (Area Under Curve).\n",
    "        \"\"\"\n",
    "        prediction_prob = prediction.flatten()  # Flatten prediction to 1D for AUC calculation\n",
    "        ground_truth_bin = ground_truth.flatten()  # Flatten ground truth to 1D\n",
    "        return roc_auc_score(ground_truth_bin, prediction_prob)\n",
    "\n",
    "    def iou(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Calculates Intersection over Union (IoU).\n",
    "        \"\"\"\n",
    "        prediction_bin, ground_truth_bin = self.binarize(prediction, ground_truth)\n",
    "        intersection = np.sum(prediction_bin & ground_truth_bin)\n",
    "        union = np.sum(prediction_bin | ground_truth_bin)\n",
    "        return intersection / union if union > 0 else 0\n",
    "\n",
    "    def evaluate(self, prediction, ground_truth):\n",
    "        \"\"\"\n",
    "        Evaluates the model's prediction against the ground truth.\n",
    "        Returns:\n",
    "            dict: Dictionary containing all evaluation metrics.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            \"Accuracy\": self.accuracy(prediction, ground_truth),\n",
    "            \"Sensitivity\": self.sensitivity(prediction, ground_truth),\n",
    "            \"Specificity\": self.specificity(prediction, ground_truth),\n",
    "            \"F1 Score\": self.f1_score(prediction, ground_truth),\n",
    "            \"AUC\": self.auc(prediction, ground_truth),\n",
    "            \"IoU\": self.iou(prediction, ground_truth),\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "\n",
    "\n",
    "def load_mask_from_gif(gif_path):\n",
    "    \"\"\"\n",
    "    Load mask ground truth from .gif file.\n",
    "    \"\"\"\n",
    "    img = Image.open(gif_path)\n",
    "    img = img.convert(\"L\")  # Convert to Grayscale\n",
    "    return np.array(img)\n",
    "\n",
    "ground_truth_path = 'C:\\\\Users\\\\UCL\\\\Desktop\\\\Do\\\\datasets\\\\DRIVE\\\\DRIVE\\\\test\\\\1st_manual\\\\01_manual1.gif'\n",
    "ground_truth = load_mask_from_gif(ground_truth_path)\n",
    "\n",
    "evaluator = ModelEvaluation(threshold=0.5)\n",
    "\n",
    "# Đánh giá kết quả\n",
    "metrics = evaluator.evaluate(binary_mask, ground_truth)\n",
    "\n",
    "# In kết quả đánh giá\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Do_ROP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
